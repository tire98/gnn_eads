# Configuration file for setting the hyperparameter for GNN model training with train_GNN.py

[graph]

voronoi_tol = 0.5               # Applied to all pairs of elements
scaling_factor = 1.5            # For atomic radii of metals
second_order = false            # Whether to comprise also the NNs of the metals direclt interacting with the adsorbate
edge_features = false           # Whether to include edge features
aromatic_features = false       # Whether to include aromatic features
ring_features = false           # Whether to include ring features
radical_features = true        # Whether to include radical features
relax = false                   # Whether to relax the structure for feature extraction; important for aromaticity
num_el = true                  # Whether to include the number of radical or use one hot encoding
write_db = false                # Whether filtered database should be written
family= ["radicals"] # list of families which are used for training; family key must be present in database

[train]  # Training related: All hyperparams except architecture-related ones

splits = 10                      # Initial splits of the starting dataset for train/val/test sets creation
test_set = true                  # whether generate test set or just split among train/val
batch_size = 16
epochs = 200
target_scaling = "std"      # Target scaling approach ("std" only available for now)
loss_function = "mae"       # Loss function of the training
lr0 = 1e-3                  # Initial learning rate (lr)
patience = 7                # Patience of the lr-scheduler
factor = 0.7                # Decreasing factor of the lr-scheduler
minlr = 1e-7                # Minimum lr of the lr-scheduler
eps = 1e-9                  # adam eps for ensuring numerical stability of the algorithm
weight_decay = 0
amsgrad = true              # Include amsgrad addition of adam
seed = 42                   # Seed for random number generation

[architecture]  # All the hyperparameters defining the model architecture

dim = 160                   # dimension of the layers
sigma = "ReLU"              # Activation function
bias = false                # Whether allowing bias in all layer formulas
n_linear = 0                # Number of fully connected layers
n_conv = 3                  # Number of convolutional layers
conv_layer = "SAGE"         # Convolutional layer
adj_conv = false            # Whether adjust convolutional layer with fully connected one just before
conv_normalize = false
conv_root_weight = true
pool_layer = "GMT"          # Pooling layer
pool_ratio = 0.25           # Poling ratio params for GMT
pool_heads = 1              # Number of heads for GMT                 
pool_seq = "1"
pool_layer_norm = false
bias_input = true                                                                      
bias_conv = false                                                                      
bias_dense = false                                                                     
bias_adj = false 