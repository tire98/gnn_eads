14-Apr-2023, 11:02:34
Device = NVIDIA A100-SXM4-80GB MIG 3g.40gb
Training time = 2.40 min
---------------------------------------------------------
GRAPH REPRESENTATION PARAMETERS
Voronoi tolerance = 0.5 Angstrom
Atomic radius scaling factor = 1.5
Second order metal neighbours inclusion = False
---------------------------------------------------------
GNN ARCHITECTURE
Activation function = ReLU
Convolutional layer = SAGE
Pooling layer = GMT
Number of convolutional layers = 3
Number of fully connected layers = 0
Depth of the layers = 160
Bias presence in inout layer = True
---------------------------------------------------------
TRAINING PROCESS
Dataset Size = 1635
Data Split (Train/Val/Test) = 80-10-10 %
Target scaling = std
Target (train+val) mean = -26.920055 eV
Target (train+val) standard deviation = 13.232637 eV
Epochs = 200
Batch size = 16
Optimizer = Adam
Learning Rate scheduler = Reduce Loss On Plateau
Initial learning rate = 0.001
Minimum learning rate = 1e-07
Patience (lr-scheduler) = 7
Factor (lr-scheduler) = 0.7
Loss function = mae
---------------------------------------------------------
GNN PERFORMANCE
Test set size = 163
Mean Bias Error (MBE) = -0.067 eV
Mean Absolute Error (MAE) = 0.239 eV
Root Mean Square Error (RMSE) = 0.343 eV
Mean Absolute Percentage Error (MAPE) = 1.510 %
Error Standard Deviation = 0.336 eV
R2 = 0.999 
---------------------------------------------------------
OUTLIERS (TEST SET)
01) N1-Cu7            Error: -1.94 eV    (index=4)
02) H2O1-(g)          Error: -1.41 eV    (index=160)
